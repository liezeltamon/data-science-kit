---
title: "singlecell"
format: html
---

# Single-cell sequencing protocols
1. 3 types of protocols mainly differentiated by cell isolation method
   - Commercial Fluidigm C1 microfluidic chip based
   - Well plate based
   - Microfluidics device based 
     + Use device to capture single cell in an emulsion or droplet
     + Captures only 3' of transcript (R2 end, R1 + cell barcode + UMI at 5')
     + 10x Genomics Chromium (outperformed two other similar methods but 2x more expensive per cell, Zhang et al. 2019)
2. Potential biases
   - Protocols have biases for certain transcripts
     + "10X Genomics favored the capture and amplification of shorter genes and genes with higher GC content" - Scbp (Single-cell best practices)
   - Some cell states are more vulnerable to dissociation (e.g. non-neuronal cells survive better than neurons - Darmanis et al. 2015, Scbp)

# Raw data processing

1. Get FASTQ files (Sequence + quality)
   - Manual download from https://www.ebi.ac.uk/ena/browser/view/\<SR ID\>
     + Batch download using SRA Toolkit:
     
       ```{bash}
       #| eval: false
       fastq-dump --split-files --gzip SRR6334436
       ```
       
2. Check FASTQ sequence read quality
   - FastQC
   - MultiQC can be used to combine FastQC reports from each FASTQ

### Read mapping/alignment and quantification

Tools below can do both alignment and quantification but they can be used in combination e.g. 1 tool for alignment + 1 tool for quantification (will use BAM from alignment method).

1. Cell Ranger
   - Preparing SRA data for Cell Ranger
     + https://kb.10xgenomics.com/hc/en-us/articles/115003802691-How-do-I-prepare-Sequence-Read-Archive-SRA-data-from-NCBI-for-Cell-Ranger-
     + "Cell Ranger requires FASTQ file names to follow the `bcl2fastq` file naming convention." 
        - `[Sample Name]`\_S1_L00`[Lane Number]`\_`[Read Type]`\_001.fastq.gz
2. Kallisto
3. STARsolo (available in latest STAR versions)

# Analysis - General Remarks

1.  Check first individual datasets before integrating. Check consistency between technical and biological replicates.

### Transformations

1. Comparison and benchmarking study from Wolfgang Huber
   - Comparison to identify conceptual differences i.e. vulnerability of size factor confounding, dealing with mean-variance relationship, dealing with bimodal expression of genes
   - Benchmarking to identify performance differences
     + They measured performance based on how useful the methods are in understanding variety of cell types and states via k-NN graphs
     + They recommended benchmarking, measuring performance based on marker gene identification
   - Take-aways
     + Delta-based methods have better overall performance compared with residual-based and latent-based methods (more complicated methods)
     + Dimension reduction via PCA improves performance
     + For initial analysis of individual datasets, just try delta based methods particularly the log transformation on Seurat first
       - Avoid using CPM as it overestimates the overdispersion
       - Overdisperson of 0.05 performs well
       - Check confounding effect of size factors as delta-based methods are more vulnerable to do this compare with other types of approaches

     + Delta-based and residuals-based methods complement each other based on their conceptual differences so probably useful to see that results are robust between these two types
       - Simplest method with good performance (good starting point) is the **log(y/s +yo) with yo =1 followed by PCA**.
       
### CITE-seq / Feature barcoding and cell hashing

- CITE-seq 
  + Uses DNA-barcoded antibodies to measure surface proteins simultaneously with RNA
  + Before partitioning cells in GEMs, cells get tagged by DNA-barcoded antibodies targeting markers
  + DNA barcode will then be treated just like the other molecules 
  + So on top of getting RNA profile of single cells, with CITE-seq we can get information on expression of surface protein markers per cell
  + Amount of DNA barcode coming from antibody will reflect also level of surface protein
  + Library construction -  size selection is used to separate the amplified cDNA molecules for 3' Gene Expression and Cell Surface Protein Library Construction (product giude, Chromium Next GEM Single Cell 3' HT Reagent Kits v3.1 (Dual Index))
    - Separate library construction because the DNA barcode attached to antibody already have the sequencing read 2 (library specifc, used for PCR amplication?), meanwhile for the RNA first strands, the sequencing read 2 still have to be ligated to complete the fragment for sequencing

- Cell hashing
  + The same principle as CITE-seq but because the DNA-barcoded antibodies are used to tag different samples, antibodies can just target some ubiquitously expressed surface protein (across samples) instead of specific marker proteins
  
  
# Analysis

## Quality control

### Empty droplets

- Use latest technology-specific expected percentage of empty droplets to help decide threshold for removing empty droplets

### Doublets

- Use latest technology-specific expected percentage of doublets to help decide threshold for removing doublets

- DoubletFinder
  + `modelHomotypic()` - operates based on expectation that homotypic doublets will likely be between cells that dominate sample so function use information about clusters and their sizes

### Ambient RNA

- Approaches

  + Measure ambient RNA signal and adjust each cell count for their ambient RNA content
    - This could convert counts to floating points, which may not be amenable for other downstream steps
  + Measure ambient RNA signal and remove cells dominated by that signal
  + Measure ambient RNA signal, see if you can proceed without removing cells or adjusting for ambient RNA, continue with usual workflow up to clustering and then see the level of ambient RNA contamination per cluster

- Earlier methods used possibly empty droplets with ambient RNA to estimate ambient solution profile but the decontX method (`celda:decontX()`) uses different way such that you can apply it even after removing those empty droplets

### Mitochondrial content

- RNAs in mitochondria can be both mitochondrial and nuclear genome encoded
  + Those human gene symbols with "M^T-" are the ones encoded by the mitochondrial genome

### **Barcode swapping (earlier called as 'index hopping')**

- Given a multiplexed pool of samples, we identify potential swapping events as transcript molecules that share the same combination of UMI sequence, assigned gene and cell barcode across samples. We only keep the molecule if it has dominant coverage in a single sample, which is likely to be its original sample; we remove all (presumably swapped) instances of that molecule in the other samples. - OSCA

## Demultiplexing

### HTODemux()

- Starts with clustering cells based on HTO vectors
- `HTODemux(positive.quantile)` - Per HTO, identifies the cluster of cells with lowest average for the HTO, fits a negative binomial distribution to values of that cluster and then identifies the value at given positive.quantile (this value is outputed per HTO while HTODemux is running), if a cell has higher HTO value that this value at that quantile, cell is considered to be positive for that HTO
- Revisit CLR nomalisation (used for protein data normalisation) applied to HTO data?

- **Try using CellHashR for consensus approach combining different methods**

## Normalisation

- Motivation 
  + Account for systematic differences across samples or cells e.g. differences in sequencing depth / library size
  
- `Seurat::NormalizeData()` always works off of the counts slots and will overwrite the data slot (https://github.com/satijalab/seurat/issues/2362)

- **Understand** `scuttle::computePooledFactors()`
  + Typical library size normalisation can be insufficient because of compositional biases (e.g. presence of DE genes), wherein some cells can be expected to have high expression of some marker genes for example while other cells expected not to expressed those markers
  + DESeq or TMM normalization are more robust to DE but rely on the calculation of ratios of counts between cells. This is not straightforward in scRNA-seq data, where the high frequency of dropout events interferes with stable normalization - original `scuttle::computePooledFactors()` paper
  + This `scuttle::computePooledFactors()` was made to improve normalisation by decreasing incidence of zeroes or dropouts by pooling cells
  
- Removing some highly expressed genes before normalisation
  + High gene counts can skew normalisation so some people may remove them before normalisation
  + Maybe can do normalisation with all genes then if highly expressed genes do not significantly vary, can safely remove them then redo normalisaiton without these genes
  + MALAT1 tend to be within nucleus so if you see it to be high in cytoplasm, could be sign of bad cell health - [10x Genomics article on this](https://kb.10xgenomics.com/hc/en-us/articles/360004729092-Why-do-I-see-high-levels-of-Malat1-in-my-gene-expression-data)

### Normalisation methods

- LogNormalise
  + Per cell, counts are divided by a cell-specific size factor proportional to the library size
  + Then log transformation is done to convert expression data, often right skewed (closer to a log normal distribution), into a distribution that is closer to a normal distribution, also reducing impact of outlier values
  
- Centered log-ratio (CLR)
  + Per cell, values are transformed such that each proportion of features sum up to 1 (100%) 
  + Per cell, take the natural logarithm of the ratio of feature values to their geometric mean 
  + Transformed values are then centered per FEATURE i.e. unlike logNormalise and RC, this method does transformation across cells
  
- Relative counts (RC)
  + logNormalise but skipping log transformation
  
- SCTransform 
  + Modelling depedence of variance with log UMI (y ~ log_umi) using negative binomial expression?
  + Calculates size factors per gene groups based on mean expression
  
### SCTransform

- Output (https://github.com/satijalab/seurat/issues/1957)
  + counts slot - Sequencing depth-corrected counts "reversed transforming" from Pearson residuals in scale.data slot (https://github.com/satijalab/seurat/issues/2457)
  + data slot - calculated from residuals (?) - https://github.com/satijalab/seurat/issues/3841
  + scale.data slot - Pearson residuals (residuals from model divided by expected standard deviation of residuals, centered by default) are taken as the scaled expression values
   - "Positive residuals for a given gene in a given cell indicate that we observed more UMIs than expected given the gene’s average expression in the population and cellular sequencing depth, while negative residuals indicate the converse." [sctransform 2019 paper](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1)
  
## Find variable features

- Point of methods is to stabilize the variance across the mean expression of genes, making it easier to identify genes whose variability is not simply due to mean expression

### Methods

- Variance stabilising transformation (vst)
- scran::modelGeneVar()
  + Model mean-variance trend and then the log-expression profiles per gene are decomposed into technical (value predicted by model describing mean-variance trend) and biological variance (total variance of log counts across cells per gene - estimated technical variance)
  + Strictly speaking, the interpretation of the fitted trend as the technical component assumes that the expression profiles of most genes are dominated by random technical noise

## Scaling data

- `Seurat::ScaleData()` works off of the normalized data (data slot) (https://github.com/satijalab/seurat/issues/2362)
- Seurat scales only variable features
- "Default is to scale only the variable features" (https://github.com/satijalab/seurat/issues/2365)

## Dimensionality reduction

### PCA

- "The default for `Seurat::RunPCA()` is to use the variable features, but there is a requirement that the features are scaled. It will issue a warning when you request features not in scaled data, but will still proceed with the subset that are scaled." (https://github.com/satijalab/seurat/issues/2365)

- Use scran::fixedPCA() to "perform a PCA where the desired number of components is known ahead of time"
  + By default, scran::fixedPCA() will compute the first 50 PCs and store them in the reducedDims() of the output SingleCellExperiment object, as shown below (set seed before)
  + Internally uses BiocSingular::runSVD(center = TRUE) but not argument to scale as in scater::runPCA() but plotting functions in scater e.g. scrater::plotHeatmap() have scale and center arguments

## Clustering

- `Seurat::FindNeighbors()` vs. `Seurat::FindClusters()`
  + `FindNeighbors()` is only concerned with finding the k nearest neighbours of each data point based on some similarity or distance metric and computes nearest neighbour graph and optionally, shared nearest neighbour graph (SNN)
   - The SNN graph is a representation of these shared nearest neighbor relationships. Each data point is a node in the graph, and there's an edge (a connection) between two nodes if they share a significant number of nearest neighbors. The strength of the connection can be determined by how many neighbors they share in common.
   - In contrast, in an NN graph, edge is binary i.e. two data points (not) connected are (not) neighbors.
   - In summary, while both NN and SNN graphs involve connecting data points based on nearest neighbors, the key distinction is that NN graphs have binary connections to a fixed number of nearest neighbors, whereas SNN graphs capture shared neighbor relationships with varying connection strengths. SNN graphs are particularly useful for identifying clusters or communities within datasets because they emphasize data points that are part of the same local structures.
  
  + `FindClusters()` has to cluster cells based on graph of shared nearest neighbors
    - Resolution parameter above (below) 1.0 to tell clustering algorithm e.g. Louvain to find more smaller or fewer, larger clusters
    
## Identifying cluster markers

- Points is to find features that can uniquely define a cluster
- Straightforward approach is to test per feature, differential expression between two clusters

- `Seurat::FindAllMarkers()` - comparing a cluster against all remaining cells from all other clusters (https://github.com/satijalab/seurat/issues/1075)
- `Seurat::FindConservedMarkers()` - find differentially expressed markers between clusters that are conserved across other grouping variable e.g. batch; see [vignette](https://satijalab.org/seurat/articles/integration_introduction.html)

- `scran::getClusteredPCs()` to select priori choice of number of PCs - We perform clustering (graph-based by default, see Basic Section 5.2) on the first d*PCs and only consider the values of d that yield no more than d + 1 clusters; assumption is number of required PCs could be estimated as number of expected subpopulations - 1 i.e. smallest number of PCs to separate each subpopulation

- `scran::quickCluster` - function to quickly do clustering even just from normalised counts because it does PCA etc. in one go / function

## Integration

### Methods

1. Seurat::IntegrateLayers() - refer to https://github.com/satijalab/seurat/issues/8653 to understand evolution of IntegrateData() to IntegrateLayers() (v5)

### Metrics

1. Average silhouette width - Measures how similar a cell is to its own cluster compared to other clusters. Higher silhouette scores indicate better separation between clusters.

2. Local inverse Simpson’s Index (LISI) - "defines the effective number of datasets in a neighborhood. Neighborhoods represented by only a single dataset get an iLISI of 1, while neighborhoods with an equal number of cells from two datasets get an iLISI of 2. Note that even under ideal mixing, if the datasets have different numbers of cells, iLISI would be less than 2" - From Harmony paper

3. Adjusted Rand Index (ARI) - measure of the similarity between two data clusterings. It is a correction of the Rand Index, which is a basic measure of similarity between two clusterings, but it has the disadvantage of being sensitive to chance (https://oecd.ai/en/catalogue/metrics/adjusted-rand-index-%28ari%29#:~:text=The%20Adjusted%20Rand%20Index%20(ARI,of%20being%20sensitive%20to%20chance.)

4. kBET metric - measures batch mixing on the local level using a predetermined number of nearest neighbors, which are selected around each data point by distance, to compute the local batch label distribution (doi: 10.1186/s13059-019-1850-9)

# Single-cell ATAC-seq

## Analysis

### General notes

- scATAC-seq data is more sparse than scRNA-seq data because we are profiling DNA and in theory, per cell, we should only get, 0, 1 or 2 (for diploid genome that behave consistently although it in reality behavior between alleles could be stochastic) counts per open region fragment

- If you want to detect rare cell types, probably do not do peak calling which lowers the actual resolution of sequencing (by binning signal) so you might lose low signal peaks present in rare cell types
  
  + In scATAC-seq, peak calling might not be applicable, instead we can do tiling i.e. binning signal per single cell? (bin resolution used in ArchR according to Ravza is 500 bp)
  
- In ATAC-seq using Tn5, "fragment" is the DNA fragment bound by the Tn5 cut

- scATAC more high-dimensional than scRNA because the features for the former, which are the DNA regions / peaks, can vary in number and exceed number of genes depending on the resolution used

### Quality control

- Number of unique nuclear fragments
- Signal-to-noise background ratio
  + Determined using TSS content i.e. we expect TSS to be enriched in the data
- Fragment size distribution

### Compositional analysis

- Simply comparing proportions can be misleading because the limit on the capacity of cells that can be assayed/captured can artificially alter the composition of cells in a condition (explained in Scbp)
- Two types of methods: 1) requires cell annotation e.g. scCODA 2) uses KNN graph e.g. MiloR
  + Choosing depends on how robust is the clustering; 2nd type of method useful if working with data where hard boundaries between cell populations may not be advisable or practical such as developmental data or looking at states within a cell types 

# Python single cell analysis

# CellRanger vs. CellBender

- Output counts highly correlated but CellBender counts are lower because:
  + It removes barcodes likely to be ambient
  + It removes counts from genes likely from ambient - probably based on modelling of ambient from barcodes likely to be empty and contain only ambient RNA
  
# Bioconductor workflow

## SingleCellExperiment class to store single-cell data

- Unlike the Seurat workflow, the Bioconductor single-cell workflow involves multiple packages (70+ single-cell-related Bioconductor packages), each performing a step or subset of steps in the workflow
- The use of the SCE class for storing single-cell data allows these packages to operate together
- SCE has slots for different types of data, more often it expects a certain type of data for each of that slot
- "One of the major advantages of using the SingleCellExperiment is that operations on the rows or columns of the expression data are synchronized with the associated annotation" - OSCA
- The major slots, assays, colData, rowData, and metadata, are inherited from SummarizedExperiment (SE) class, so methods for SE should be applicable for SCE class but due to the nature of single-cell data, there is a need for single-cell specific slots (reducedDims, alternative experiments), hence the development of the SCE class

### Alternative experiments in SCE object

- 'The SingleCellExperiment class provides the concept of "alternative Experiments” where we have data for a distinct set of features but the same set of samples/cells' - OSCA
- Any SE or SCE can be stored as alternative experiment

### Plotting

- `scater::plotScater()` - Cumulative proportion of library (y) accounted by number of variable features (x) for each cell in a SCE object
